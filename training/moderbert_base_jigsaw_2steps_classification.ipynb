{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPVRLYfYr0Sm"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets accelerate bitsandbytes scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "43-wPUAfs8z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Jigsaw Toxic Comment dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/...\")\n",
        "\n",
        "# Define fine-grained labels\n",
        "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "df[label_cols] = df[label_cols].fillna(0).astype(int)\n"
      ],
      "metadata": {
        "id": "heYhKvvbtMIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New binary label: 1 if any fine-grained label is 1\n",
        "df[\"toxic_binary\"] = df[label_cols].max(axis=1)\n",
        "print(\"Binary toxic label counts:\")\n",
        "print(df[\"toxic_binary\"].value_counts())\n",
        "\n",
        "df_binary = df[[\"comment_text\", \"toxic_binary\"]]\n",
        "df_fine = df[df[\"toxic_binary\"] == 1][[\"comment_text\"] + label_cols]\n"
      ],
      "metadata": {
        "id": "WkNvg_AbuCYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Convert to Hugging Face Datasets\n",
        "dataset_binary = Dataset.from_pandas(df_binary)\n",
        "dataset_fine = Dataset.from_pandas(df_fine)\n",
        "\n",
        "# Split each into train/test\n",
        "binary_data = dataset_binary.train_test_split(test_size=0.1, seed=42)\n",
        "fine_data = dataset_fine.train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "train_binary = binary_data[\"train\"]\n",
        "eval_binary = binary_data[\"test\"]\n",
        "\n",
        "train_fine = fine_data[\"train\"]\n",
        "eval_fine = fine_data[\"test\"]\n"
      ],
      "metadata": {
        "id": "3IS6_FamuUMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"answerdotai/ModernBERT-base\"\n",
        "\n",
        "tokenizer_binary = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model_binary = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, trust_remote_code=True)\n"
      ],
      "metadata": {
        "id": "dNntVF4Ku_hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_binary(example):\n",
        "    tokens = tokenizer_binary(example[\"comment_text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "    tokens[\"labels\"] = int(example[\"toxic_binary\"])\n",
        "    return tokens\n",
        "\n",
        "train_binary = train_binary.map(tokenize_binary)\n",
        "eval_binary = eval_binary.map(tokenize_binary)\n",
        "\n",
        "train_binary.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "eval_binary.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
      ],
      "metadata": {
        "id": "DCKvr1jhvDW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "binary_args = TrainingArguments(\n",
        "    output_dir=\"./binary_results\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=3,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    logging_steps=50,\n",
        "    save_total_limit=2\n",
        ")\n",
        "\n",
        "from transformers import Trainer\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_binary_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"f1\": f1_score(labels, preds)\n",
        "    }\n",
        "\n",
        "trainer_binary = Trainer(\n",
        "    model=model_binary,\n",
        "    args=binary_args,\n",
        "    train_dataset=train_binary,\n",
        "    eval_dataset=eval_binary,\n",
        "    tokenizer=tokenizer_binary,\n",
        "    compute_metrics=compute_binary_metrics\n",
        ")\n",
        "\n",
        "trainer_binary.train()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Run predictions on the eval set\n",
        "binary_preds = trainer_binary.predict(eval_binary)\n",
        "\n",
        "# Get predicted class labels\n",
        "logits = binary_preds.predictions\n",
        "preds = np.argmax(logits, axis=1)\n",
        "\n",
        "# True labels\n",
        "true = binary_preds.label_ids\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(true, preds, target_names=[\"non-toxic\", \"toxic\"], digits=4))\n",
        "\n"
      ],
      "metadata": {
        "id": "X5yEoEE0vE-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/...\"\n",
        "model_binary.save_pretrained(save_path)\n",
        "tokenizer_binary.save_pretrained(save_path)\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "logits = binary_preds.predictions\n",
        "preds = np.argmax(logits, axis=1)\n",
        "true = binary_preds.label_ids\n",
        "\n",
        "report = classification_report(true, preds, target_names=[\"non-toxic\", \"toxic\"], digits=4)\n",
        "\n",
        "# Save to Drive\n",
        "with open(\"/content/drive/MyDrive/...\", \"w\") as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(\"âœ… Report saved to Drive.\")\n",
        "from google.colab import files\n",
        "files.download(report_path)\n",
        "\n",
        "df_fine.to_csv(\"/content/drive/MyDrive/...\", index=False)\n"
      ],
      "metadata": {
        "id": "DBre-hTViRMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "binary_model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/...\")\n",
        "binary_tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/...\")\n"
      ],
      "metadata": {
        "id": "TjRFSZFevNMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Reload df_fine\n",
        "\n",
        "import pandas as pd\n",
        "df_fine = pd.read_csv(\"/content/drive/MyDrive/...\")\n"
      ],
      "metadata": {
        "id": "zvWVxUtpvR2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "fine_dataset = Dataset.from_pandas(df_fine)\n",
        "fine_split = fine_dataset.train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "train_fine = fine_split[\"train\"]\n",
        "eval_fine = fine_split[\"test\"]\n"
      ],
      "metadata": {
        "id": "wP8AcreDvkyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"answerdotai/ModernBERT-base\"\n",
        "\n",
        "tokenizer_fine = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model_fine = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6, trust_remote_code=True)\n",
        "def tokenize_and_format_fine(example):\n",
        "    tokens = tokenizer_fine(example[\"comment_text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "    tokens[\"labels\"] = [\n",
        "        float(example[\"toxic\"]),\n",
        "        float(example[\"severe_toxic\"]),\n",
        "        float(example[\"obscene\"]),\n",
        "        float(example[\"threat\"]),\n",
        "        float(example[\"insult\"]),\n",
        "        float(example[\"identity_hate\"])\n",
        "    ]\n",
        "    return tokens\n",
        "\n",
        "train_fine = train_fine.map(tokenize_and_format_fine)\n",
        "eval_fine = eval_fine.map(tokenize_and_format_fine)\n",
        "\n",
        "train_fine.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "eval_fine.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
      ],
      "metadata": {
        "id": "d2sEcR12wM-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "class FineTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fn = nn.BCEWithLogitsLoss()\n",
        "        loss = loss_fn(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "fine_args = TrainingArguments(\n",
        "    output_dir=\"./fine_results\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=3,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    logging_steps=50,\n",
        "    save_total_limit=2\n",
        ")\n",
        "trainer_fine = FineTrainer(\n",
        "    model=model_fine,\n",
        "    args=fine_args,\n",
        "    train_dataset=train_fine,\n",
        "    eval_dataset=eval_fine,\n",
        "    tokenizer=tokenizer_fine,\n",
        ")\n",
        "\n",
        "trainer_fine.train()\n",
        "\n",
        "# Get predictions\n",
        "preds = trainer_fine.predict(eval_fine)\n",
        "logits = preds.predictions\n",
        "true_labels = preds.label_ids\n",
        "\n",
        "# Convert logits to binary labels using sigmoid + threshold\n",
        "probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
        "pred_labels = (probs >= 0.5).astype(int)\n",
        "\n",
        "# Define label names\n",
        "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "\n",
        "# Generate report\n",
        "report = classification_report(true_labels, pred_labels, target_names=label_cols, digits=4, zero_division=0)\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "KzREp4xZwUyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/...\", \"w\") as f:\n",
        "    f.write(report)\n",
        "    from google.colab import files\n",
        "files.download(\"/content/drive/MyDrive/...\")\n"
      ],
      "metadata": {
        "id": "NIGMSDPm2t23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fine.save_pretrained(\"/content/drive/MyDrive/...\")\n",
        "tokenizer_fine.save_pretrained(\"/content/drive/MyDrive/...\")\n"
      ],
      "metadata": {
        "id": "eLlbEKQ73MvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load binary classifier\n",
        "binary_model_path = \"/content/drive/MyDrive/...\"\n",
        "tokenizer_binary = AutoTokenizer.from_pretrained(binary_model_path)\n",
        "model_binary = AutoModelForSequenceClassification.from_pretrained(binary_model_path).to(device)\n",
        "\n",
        "# Load fine-grained classifier\n",
        "fine_model_path = \"/content/drive/MyDrive/...\"\n",
        "tokenizer_fine = AutoTokenizer.from_pretrained(fine_model_path)\n",
        "model_fine = AutoModelForSequenceClassification.from_pretrained(fine_model_path).to(device)\n"
      ],
      "metadata": {
        "id": "f004AhaT3xTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "\n",
        "def predict_toxicity(comment):\n",
        "    # Stage 1: Binary prediction\n",
        "    binary_inputs = tokenizer_binary(comment, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        binary_outputs = model_binary(**binary_inputs)\n",
        "        binary_pred = torch.argmax(binary_outputs.logits, dim=1).item()\n",
        "\n",
        "    if binary_pred == 0:\n",
        "        return {\"binary\": \"non-toxic\", \"subtypes\": None}\n",
        "\n",
        "    # Stage 2: Fine-grained prediction\n",
        "    fine_inputs = tokenizer_fine(comment, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        fine_outputs = model_fine(**fine_inputs)\n",
        "        probs = torch.sigmoid(fine_outputs.logits).cpu().numpy()[0]\n",
        "\n",
        "    # Apply threshold of 0.5\n",
        "    subtypes = {label: round(float(prob), 2) for label, prob in zip(label_cols, probs) if prob >= 0.5}\n",
        "\n",
        "    return {\"binary\": \"toxic\", \"subtypes\": subtypes}\n"
      ],
      "metadata": {
        "id": "1LlZpoFM33ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment = \"you are stupid.\"\n",
        "result = predict_toxicity(comment)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "W7cWg02536CN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}