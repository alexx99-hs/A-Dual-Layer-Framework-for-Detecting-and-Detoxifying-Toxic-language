{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets accelerate bitsandbytes\n"
      ],
      "metadata": {
        "id": "HSdmM3fodLZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "0ZY1-sLJds7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Update the path if your file is somewhere else\n",
        "csv_path = \"/content/drive/MyDrive/...\"\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Check the first few rows\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "Gdm_BK_zd4hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load training set\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/...\")\n",
        "\n",
        "# Load test set and test labels\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/...\")\n",
        "test_labels_df = pd.read_csv(\"/content/drive/MyDrive/...\")\n",
        "# Merge test data and labels on 'id'\n",
        "test_full = test_df.merge(test_labels_df, on=\"id\")\n",
        "\n",
        "# Keep only fully labeled examples (drop rows with any -1s)\n",
        "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "test_filtered = test_full[~test_full[label_cols].isin([-1]).any(axis=1)].copy()\n",
        "from datasets import Dataset\n",
        "\n",
        "# Prepare training dataset\n",
        "train_df[label_cols] = train_df[label_cols].astype(int)\n",
        "train_hf = Dataset.from_pandas(train_df[[\"comment_text\"] + label_cols])\n",
        "\n",
        "# Prepare eval dataset\n",
        "test_filtered[label_cols] = test_filtered[label_cols].astype(int)\n",
        "eval_hf = Dataset.from_pandas(test_filtered[[\"comment_text\"] + label_cols])\n"
      ],
      "metadata": {
        "id": "b7XWB9OleQKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"answerdotai/ModernBERT-base\"\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6, trust_remote_code=True)\n"
      ],
      "metadata": {
        "id": "pi3EJI--fga1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_format(example):\n",
        "    # Tokenize the text\n",
        "    tokens = tokenizer(example[\"comment_text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "    # Add multi-label targets\n",
        "    tokens[\"labels\"] = [\n",
        "        float(example[\"toxic\"]),\n",
        "        float(example[\"severe_toxic\"]),\n",
        "        float(example[\"obscene\"]),\n",
        "        float(example[\"threat\"]),\n",
        "        float(example[\"insult\"]),\n",
        "        float(example[\"identity_hate\"])\n",
        "    ]\n",
        "    return tokens\n",
        "\n",
        "# Apply to both datasets\n",
        "train_dataset = train_hf.map(tokenize_and_format)\n",
        "eval_dataset = eval_hf.map(tokenize_and_format)\n",
        "\n",
        "# Format for PyTorch\n",
        "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "eval_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
      ],
      "metadata": {
        "id": "Y72YtNzefwzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q scikit-learn\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
        "\n",
        "    # Threshold at 0.5\n",
        "    preds = (probs >= 0.5).astype(int)\n",
        "\n",
        "    # Flatten for metrics like accuracy\n",
        "    labels_flat = labels.reshape(-1)\n",
        "    preds_flat = preds.reshape(-1)\n",
        "    probs_flat = probs.reshape(-1)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels_flat, preds_flat),\n",
        "        \"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
        "        \"f1_micro\": f1_score(labels, preds, average=\"micro\", zero_division=0),\n",
        "        \"roc_auc\": roc_auc_score(labels, probs, average=\"macro\"),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "GpYoxhPfku5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Custom Trainer to compute multi-label classification loss\n",
        "class MultiLabelTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fn = nn.BCEWithLogitsLoss()\n",
        "        loss = loss_fn(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ],
      "metadata": {
        "id": "IM55vcytio4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=3,  # â†‘ from 1\n",
        "    learning_rate=2e-5,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "trainer = MultiLabelTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "id": "p4JNGI5vTVsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming 'trainer' and 'eval_dataset' are defined from the previous code\n",
        "predictions = trainer.predict(eval_dataset)\n",
        "\n",
        "# Extract logits and labels\n",
        "logits = predictions.predictions\n",
        "labels = predictions.label_ids\n",
        "\n",
        "# Convert logits to probabilities using sigmoid\n",
        "probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
        "\n",
        "# Threshold at 0.5 to get predictions\n",
        "preds = (probs >= 0.5).astype(int)\n",
        "\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(labels, preds, target_names=label_cols, output_dict=True)\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "report_df.to_csv('classification_report.csv')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('classification_report.csv')"
      ],
      "metadata": {
        "id": "QsA7Yqiu-_Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/...\"\n",
        "# Save model\n",
        "model.save_pretrained(save_path)\n",
        "\n",
        "# Save tokenizer\n",
        "tokenizer.save_pretrained(save_path)\n"
      ],
      "metadata": {
        "id": "mGedHSAY_m8x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}