{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4rl4G3GBBJOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVTxGsAvAvJb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Load models and tokenizers\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Binary classifier\n",
        "binary_model_path = \"/content/drive/MyDrive/...\"\n",
        "tokenizer_binary = AutoTokenizer.from_pretrained(binary_model_path)\n",
        "model_binary = AutoModelForSequenceClassification.from_pretrained(binary_model_path).to(device)\n",
        "\n",
        "# Fine-grained classifier\n",
        "fine_model_path = \"/content/drive/MyDrive/...\"\n",
        "tokenizer_fine = AutoTokenizer.from_pretrained(fine_model_path)\n",
        "model_fine = AutoModelForSequenceClassification.from_pretrained(fine_model_path).to(device)\n",
        "\n",
        "# Labels\n",
        "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "\n",
        "# Inference function\n",
        "def predict_toxicity(comment):\n",
        "    # Binary classification\n",
        "    binary_inputs = tokenizer_binary(comment, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        binary_outputs = model_binary(**binary_inputs)\n",
        "        probs = torch.softmax(binary_outputs.logits, dim=1)\n",
        "        toxic_prob = probs[:, 1].item()  # probability of toxic class\n",
        "\n",
        "        # Decide label based on fixed threshold\n",
        "        binary_pred = \"toxic\" if toxic_prob >= 0.5 else \"non-toxic\"\n",
        "        if binary_pred == \"non-toxic\":\n",
        "            return {\"binary\": binary_pred, \"subtypes\": None, \"toxic_prob\": toxic_prob}\n",
        "\n",
        "    # Stage 2: Fine-grained classification\n",
        "    fine_inputs = tokenizer_fine(comment, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        fine_outputs = model_fine(**fine_inputs)\n",
        "        fine_probs = torch.sigmoid(fine_outputs.logits).cpu().numpy()[0]\n",
        "\n",
        "    subtypes = {label: round(float(prob), 2) for label, prob in zip(label_cols, fine_probs) if prob >= 0.5}\n",
        "    return {\"binary\": binary_pred, \"subtypes\": subtypes, \"toxic_prob\": toxic_prob}\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    sample = \"You're a disgusting idiot and should be banned.\"\n",
        "    result = predict_toxicity(sample)\n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n"
      ],
      "metadata": {
        "id": "IOSUYjp3Doyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "ds = load_dataset(\"textdetox/multilingual_paradetox_test\")"
      ],
      "metadata": {
        "id": "aSqa-KLwDvqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "ds = load_dataset(\"textdetox/multilingual_paradetox_test\")\n",
        "\n",
        "# Check column names in the English split\n",
        "print(ds[\"en\"].column_names)\n"
      ],
      "metadata": {
        "id": "JzlVkAZxFS6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the English test set\n",
        "ds = load_dataset(\"textdetox/multilingual_paradetox_test\")\n",
        "english_data = ds[\"en\"]\n",
        "\n",
        "# Extract raw toxic text\n",
        "toxic_sentences = english_data[\"text\"]\n",
        "\n",
        "# Run predictions\n",
        "results = [predict_toxicity(s) for s in toxic_sentences]\n"
      ],
      "metadata": {
        "id": "AjozAp5vFra2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_results = pd.DataFrame({\n",
        "    \"text\": toxic_sentences,\n",
        "    \"binary_prediction\": [r[\"binary\"] for r in results],\n",
        "    \"subtypes\": [r[\"subtypes\"] for r in results],\n",
        "    \"toxic_prob\": [r[\"toxic_prob\"] for r in results]\n",
        "})\n",
        "\n",
        "\n",
        "# Save to Drive or local\n",
        "df_results.to_csv(\"/content/drive/MyDrive/...\", index=False)\n"
      ],
      "metadata": {
        "id": "Mw0VKbaUGDSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "print(classification_report(\n",
        "    true_labels,\n",
        "    preds_adjusted,\n",
        "    labels=[0, 1],\n",
        "    target_names=[\"non-toxic\", \"toxic\"],\n",
        "    digits=4,\n",
        "    zero_division=0\n",
        "))\n"
      ],
      "metadata": {
        "id": "wh8_UDScxHsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/drive/MyDrive/...\")\n"
      ],
      "metadata": {
        "id": "3GEBJ-qZGE42"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}